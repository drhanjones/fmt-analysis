{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9dd3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d962a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set Tokenizer Root as the folder that contains different tokenizer folders  (Same instructions as before)\n",
    "# Options - (relevant ones) - \n",
    "#   babylm_full_bpe_8k - Tokenizer for 10M models, vocab size 8k\n",
    "#   babylm_full_bpe_100M_8k - Tokenizer for 100M models, vocab size 8k \n",
    "#Model's Relevant details can be found in the Model Table in the database (in rundata.xlsx)\n",
    "\n",
    "TOKENIZER_ROOT = r\"data\" \n",
    "\n",
    "def load_tokenizer(data_dir):\n",
    "    \"\"\"\n",
    "    Load tokenizer for natural stories evaluation.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The directory path where the tokenizer data is stored.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer (Tokenizer): The loaded tokenizer object.\n",
    "\n",
    "    Raises:\n",
    "        NotImplementedError: If stoi/itos is not supported or found.\n",
    "\n",
    "    \"\"\"\n",
    "    data_dir = os.path.join(TOKENIZER_ROOT, data_dir)\n",
    "    meta_path = os.path.join(data_dir, \"meta.pkl\")\n",
    "    load_meta = os.path.exists(meta_path)\n",
    "\n",
    "    if load_meta:\n",
    "        with open(meta_path, 'rb') as f:\n",
    "            meta = pickle.load(f)\n",
    "        if meta.get(\"custom_tokenizer\", False):\n",
    "            print(f\"Loading custom tokenizer from {data_dir}\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(data_dir, use_fast=False)\n",
    "        else:\n",
    "            if meta.get(\"stoi\", False):\n",
    "                raise NotImplementedError(\"stoi/itos not supported yet\")\n",
    "            else:\n",
    "                raise NotImplementedError(\"No stoi/itos found\")\n",
    "    else:\n",
    "        print(\"No meta.pkl found\")\n",
    "        raise NotImplementedError(\"No meta.pkl found\")\n",
    "\n",
    "    if not tokenizer.eos_token:\n",
    "        tokenizer.add_special_tokens({\"eos_token\": \"</s>\"})\n",
    "    if not tokenizer.pad_token:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    tokenizer.padding_side = \"left\"  # Add if needed?\n",
    "    return tokenizer\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc810a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/abishekthamma/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "#SET HF Access Key to be able to access the models since the repository is private (Will share separately)\n",
    "from huggingface_hub import login as hf_login\n",
    "\n",
    "hf_login(token=os.environ.get(\"HF_ACCESS_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02f62648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_folder_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_layer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_head",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "block_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_embd",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "batch_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "seed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "masking",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "mask_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask_decay_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "echoic_memory",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "curriculum_learning",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "curriculum_type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "log_exists",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "output_exists",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ckpt_exists",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "sample_exists",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "blimp_exists",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "wandb_exists",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "reading_time_exists",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "model_surprisal_data_exists",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "runtime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rough_sbu_estimate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epochs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wandb_runid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_iterations",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gradient_accumulation_steps",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d5f7597f-d880-4d83-a77c-a72ae0d48ace",
       "rows": [
        [
         "0",
         "5444724",
         "out-babylm_full_bpe-4x4-nomask-5444724",
         "4",
         "4",
         "128",
         "256",
         "32.0",
         "0.001",
         "1337",
         "False",
         "Non",
         "0.0",
         "1",
         "False",
         null,
         "babylm_full_bpe",
         "True",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True",
         "True",
         "0:15:38",
         "155",
         "100.8246153846154",
         "5o1o8tm8",
         "44000.0",
         "8.0"
        ],
        [
         "1",
         "5445338",
         "out-babylm_wocdes_full_bpe-4x4-nomask-5445338",
         "4",
         "4",
         "128",
         "256",
         "32.0",
         "0.0005",
         "1337",
         "False",
         "Non",
         "0.0",
         "1",
         "False",
         null,
         "babylm_wocdes_full_bpe",
         "True",
         "True",
         "True",
         "False",
         "True",
         "True",
         "True",
         "True",
         "0:15:32",
         "155",
         "100.8246153846154",
         "hffttavi",
         "44000.0",
         "8.0"
        ],
        [
         "2",
         "5492054",
         "out-babylm_full_bpe-8x8-nomask-5492054",
         "8",
         "8",
         "512",
         "512",
         "32.0",
         "0.0005",
         "1337",
         "False",
         "Non",
         "0.0",
         "1",
         "False",
         null,
         "babylm_full_bpe",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "1:03:36",
         "559",
         "403.2984615384615",
         "ddnlzu6p",
         "44000.0",
         "8.0"
        ],
        [
         "3",
         "5492134",
         "out-babylm_full_bpe-6x6-nomask-5492134",
         "6",
         "6",
         "256",
         "384",
         "32.0",
         "0.0005",
         "1337",
         "False",
         "Non",
         "0.0",
         "1",
         "False",
         null,
         "babylm_full_bpe",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "0:23:14",
         "227",
         "201.6492307692308",
         "ub67nse1",
         "44000.0",
         "8.0"
        ],
        [
         "4",
         "5496426",
         "out-babylm_full_bpe_8k-8x8-nomask-5496426",
         "8",
         "8",
         "512",
         "512",
         "32.0",
         "0.0005",
         "1337",
         "False",
         "Non",
         "0.0",
         "1",
         "False",
         null,
         "babylm_full_bpe_8k",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "True",
         "0:56:01",
         "524",
         "403.2984615384615",
         "7paxvcyz",
         "44000.0",
         "8.0"
        ]
       ],
       "shape": {
        "columns": 30,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>output_folder_name</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>n_head</th>\n",
       "      <th>block_size</th>\n",
       "      <th>n_embd</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>masking</th>\n",
       "      <th>...</th>\n",
       "      <th>blimp_exists</th>\n",
       "      <th>wandb_exists</th>\n",
       "      <th>reading_time_exists</th>\n",
       "      <th>model_surprisal_data_exists</th>\n",
       "      <th>runtime</th>\n",
       "      <th>rough_sbu_estimate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>wandb_runid</th>\n",
       "      <th>num_iterations</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5444724</td>\n",
       "      <td>out-babylm_full_bpe-4x4-nomask-5444724</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1337</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0:15:38</td>\n",
       "      <td>155</td>\n",
       "      <td>100.824615</td>\n",
       "      <td>5o1o8tm8</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5445338</td>\n",
       "      <td>out-babylm_wocdes_full_bpe-4x4-nomask-5445338</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1337</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0:15:32</td>\n",
       "      <td>155</td>\n",
       "      <td>100.824615</td>\n",
       "      <td>hffttavi</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5492054</td>\n",
       "      <td>out-babylm_full_bpe-8x8-nomask-5492054</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1337</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1:03:36</td>\n",
       "      <td>559</td>\n",
       "      <td>403.298462</td>\n",
       "      <td>ddnlzu6p</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5492134</td>\n",
       "      <td>out-babylm_full_bpe-6x6-nomask-5492134</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>256</td>\n",
       "      <td>384</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1337</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0:23:14</td>\n",
       "      <td>227</td>\n",
       "      <td>201.649231</td>\n",
       "      <td>ub67nse1</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5496426</td>\n",
       "      <td>out-babylm_full_bpe_8k-8x8-nomask-5496426</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1337</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0:56:01</td>\n",
       "      <td>524</td>\n",
       "      <td>403.298462</td>\n",
       "      <td>7paxvcyz</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id                             output_folder_name  n_layer  n_head  \\\n",
       "0  5444724         out-babylm_full_bpe-4x4-nomask-5444724        4       4   \n",
       "1  5445338  out-babylm_wocdes_full_bpe-4x4-nomask-5445338        4       4   \n",
       "2  5492054         out-babylm_full_bpe-8x8-nomask-5492054        8       8   \n",
       "3  5492134         out-babylm_full_bpe-6x6-nomask-5492134        6       6   \n",
       "4  5496426      out-babylm_full_bpe_8k-8x8-nomask-5496426        8       8   \n",
       "\n",
       "   block_size  n_embd  batch_size  learning_rate  seed  masking  ...  \\\n",
       "0         128     256        32.0         0.0010  1337    False  ...   \n",
       "1         128     256        32.0         0.0005  1337    False  ...   \n",
       "2         512     512        32.0         0.0005  1337    False  ...   \n",
       "3         256     384        32.0         0.0005  1337    False  ...   \n",
       "4         512     512        32.0         0.0005  1337    False  ...   \n",
       "\n",
       "  blimp_exists  wandb_exists  reading_time_exists  \\\n",
       "0         True          True                 True   \n",
       "1         True          True                 True   \n",
       "2         True          True                 True   \n",
       "3         True          True                 True   \n",
       "4         True          True                 True   \n",
       "\n",
       "   model_surprisal_data_exists  runtime rough_sbu_estimate      epochs  \\\n",
       "0                         True  0:15:38                155  100.824615   \n",
       "1                         True  0:15:32                155  100.824615   \n",
       "2                         True  1:03:36                559  403.298462   \n",
       "3                         True  0:23:14                227  201.649231   \n",
       "4                         True  0:56:01                524  403.298462   \n",
       "\n",
       "   wandb_runid  num_iterations  gradient_accumulation_steps  \n",
       "0     5o1o8tm8         44000.0                          8.0  \n",
       "1     hffttavi         44000.0                          8.0  \n",
       "2     ddnlzu6p         44000.0                          8.0  \n",
       "3     ub67nse1         44000.0                          8.0  \n",
       "4     7paxvcyz         44000.0                          8.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To find model name - Use rundata.xlsx file and check the model name unde \"output_folder_name\" column in the sheet Run Details. \n",
    "model_details_df = pd.read_excel(\"results/rundata.xlsx\", sheet_name=\"Run Details\")\n",
    "\n",
    "model_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b040157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fmtmodels/out-babylm_full_bpe_8k-6x6-mask_ee2000_em01-6849723',\n",
       " 'fmtmodels/out-babylm_full_bpe_8k-6x6-mask_ee004_em10-6683311',\n",
       " 'fmtmodels/out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465077',\n",
       " 'fmtmodels/out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465082',\n",
       " 'fmtmodels/out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465084',\n",
       " 'fmtmodels/out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465085',\n",
       " 'fmtmodels/out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465086',\n",
       " 'fmtmodels/out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465087',\n",
       " 'fmtmodels/out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465089',\n",
       " 'fmtmodels/out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465090']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Huggingdface list repository names -\n",
    "from huggingface_hub import list_models\n",
    "\n",
    "hf_models_list = [x.id for x in list_models(author=\"fmtmodels\")]\n",
    "hf_models_list[:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560babd",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "- Utilize hf_models_list and model_details_df to find the right model name relevant\n",
    "- Not all models are pushed to the hub yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be899216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting flash to False because wm_mask is enabled\n",
      "Setting flash to False because wm_mask is enabled\n",
      "Setting flash to False because wm_mask is enabled\n",
      "Setting flash to False because wm_mask is enabled\n",
      "Setting flash to False because wm_mask is enabled\n",
      "Setting flash to False because wm_mask is enabled\n",
      "number of parameters: 13.69M\n"
     ]
    }
   ],
   "source": [
    "HF_REPO_ROOT = \"fmtmodels\"\n",
    "model_name = \"out-babylm_full_bpe_100M_8k-6x6-mask_ee002_em10-8465084\" \n",
    "\n",
    "\n",
    "#Currently AutoModel doesn't work, so we need to import the model from model_HF and use its from_pretrained method\n",
    "from model_HF import GPT\n",
    "\n",
    "model = GPT.from_pretrained(f\"{HF_REPO_ROOT}/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205e6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4563e802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading custom tokenizer from data/babylm_full_bpe_100M_8k\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading custom tokenizer from data/babylm_full_bpe_100M_8k\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Input IDs Shape: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Input IDs Shape: \n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logits: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8000</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Logits: \n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m8000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loss <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loss \u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hidden States: \n",
       "<span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Layer 0'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Layer 1'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Layer 2'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Layer 3'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Layer 4'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Layer 5'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Layer 6'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span><span style=\"font-weight: bold\">])}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hidden States: \n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'Layer 0'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'Layer 1'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'Layer 2'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'Layer 3'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'Layer 4'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'Layer 5'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'Layer 6'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m384\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sample usage - (Only small difference to previous script)\n",
    "from rich import print\n",
    "tokenizer = load_tokenizer(\"babylm_full_bpe_100M_8k\") #Since this model required the 100M tokenizer\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "\n",
    "sample_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "input_ids = tokenizer.encode(sample_sentence, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(\"Input IDs Shape: \", input_ids.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_m1 = model(input_ids, hidden_states=True) #If you want Loss, pass expected tokens with target = tokens_to_predict\n",
    "\n",
    "\n",
    "print(\"Logits: \", outputs_m1[\"logits\"].shape)\n",
    "print(\"Loss\", outputs_m1[\"loss\"])\n",
    "print(\"Hidden States: \", [{f\"Layer {i}\": outputs_m1[\"hidden_states\"][i].shape} for i in range(len(outputs_m1[\"hidden_states\"]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7dee1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
